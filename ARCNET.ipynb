{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795a3741",
   "metadata": {},
   "source": [
    "# ARCNET\n",
    "\n",
    "## Methods\n",
    "\n",
    "#### 1. State Space Definition\n",
    "Let $\\mathcal{S}$ be the system state space where each module $m_i^{(t)}$ at time $t$ is defined as:\n",
    "\n",
    "$$m_i^{(t)} = \\{\\mathbf{W}_i, \\mathbf{b}_i, \\mathbf{p}_i^{(t)}, Q_i^{(t)}, f_i^{(t)}, A_i^{(t)}\\}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\mathbf{W}_i, \\mathbf{b}_i$: Neural network parameters  \n",
    "- $\\mathbf{p}_i^{(t)} \\in [0,1]^d$: Position on learned manifold $\\mathcal{M}$  \n",
    "- $Q_i^{(t)}$: Q-learning function (neural or tabular)  \n",
    "- $f_i^{(t)} \\in [0,1]$: Fitness score  \n",
    "- $A_i^{(t)}$: Assembly properties  \n",
    "\n",
    "#### 2. Core Mathematical Operations\n",
    "\n",
    "**2.1 Manifold Learning Component**\n",
    "\n",
    "The system learns a manifold embedding: \n",
    "\n",
    "$$\n",
    "\\mathbf{z}_i = \\text{Encoder}(\\bar{\\mathbf{x}}) \\rightarrow \\mathbf{p}_i^{(0)} = \\sigma(\\mathbf{z}_i)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\mathbf{z}_i$: Latent vector for module $i$  \n",
    "- $\\text{Encoder}(\\cdot)$: Neural encoder function  \n",
    "- $\\bar{\\mathbf{x}}$: Input data  \n",
    "- $\\sigma(\\cdot)$: Activation function (e.g., sigmoid)  \n",
    "- $\\mathbf{p}_i^{(0)}$: Initial position on manifold for module $i$  \n",
    "\n",
    "Geodesic distance on learned manifold: \n",
    "\n",
    "$$\n",
    "d_{\\mathcal{M}}(\\mathbf{p}_i, \\mathbf{p}_j) = \n",
    "\\begin{cases} \n",
    "|\\mathbf{p}_i - \\mathbf{p}_j|_2 & \\text{if } \\mathbf{T}_i = \\emptyset \\\\\n",
    "|\\mathbf{T}_i^T(\\mathbf{p}_j - \\mathbf{p}_i)|_2 \\cdot (1 + 0.1|\\kappa_i||\\mathbf{T}_i^T(\\mathbf{p}_j - \\mathbf{p}_i)|_2) & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $d_{\\mathcal{M}}(\\mathbf{p}_i, \\mathbf{p}_j)$: Geodesic distance between modules $i$ and $j$  \n",
    "- $\\mathbf{p}_i, \\mathbf{p}_j$: Positions on manifold  \n",
    "- $\\mathbf{T}_i$: Tangent space at $\\mathbf{p}_i$  \n",
    "- $\\kappa_i$: Curvature at $\\mathbf{p}_i$  \n",
    "- $|\\cdot|_2$: Euclidean norm  \n",
    "\n",
    "**2.2 Q-Learning Evolution Dynamics**\n",
    "\n",
    "Each module maintains a Q-function $Q_i: \\mathcal{S} \\times \\mathcal{A} \\rightarrow \\mathbb{R}$ updated via: \n",
    "\n",
    "$$\n",
    "Q_i(s,a) \\leftarrow Q_i(s,a) + \\alpha[R(m_{\\text{child}}) + \\gamma \\max_{a'} Q_i(s',a') - Q_i(s,a)]\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $Q_i(s,a)$: Q-value for state $s$ and action $a$ for module $i$  \n",
    "- $\\alpha$: Learning rate  \n",
    "- $R(m_{\\text{child}})$: Reward for child module  \n",
    "- $\\gamma$: Discount factor  \n",
    "- $s'$: Next state  \n",
    "- $a'$: Next action  \n",
    "- $\\max_{a'} Q_i(s',a')$: Maximum Q-value for next state  \n",
    "\n",
    "Proof of Q-Learning Convergence: Under standard assumptions (bounded rewards, sufficient exploration), this satisfies the Robbins-Monro conditions, guaranteeing convergence to $Q^*$.\n",
    "\n",
    "**2.3 Multi-Objective Fitness Function**\n",
    "\n",
    "The adaptive fitness function implements a time-varying optimization:\n",
    "\n",
    "$$\n",
    "F_i^{(t)} = w_1^{(t)} \\cdot \\text{Accuracy}_i + w_2^{(t)} \\cdot \\text{Diversity}_i + w_3^{(t)} \\cdot \\text{Entropy}_i - \\text{Penalty}_i^{(t)}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $F_i^{(t)}$: Fitness of module $i$ at time $t$  \n",
    "- $w_1^{(t)}, w_2^{(t)}, w_3^{(t)}$: Time-varying weights  \n",
    "- $\\text{Accuracy}_i$: Accuracy metric for module $i$  \n",
    "- $\\text{Diversity}_i$: Diversity metric  \n",
    "- $\\text{Entropy}_i$: Entropy metric  \n",
    "- $\\text{Penalty}_i^{(t)}$: Penalty term at time $t$  \n",
    "\n",
    "Weights evolve as: \n",
    "\n",
    "$$\n",
    "w^{(t)} = \n",
    "\\begin{cases} \n",
    "(1.5w_n, 1.2w_e, 0.8w_a) & \\text{if } t < 0.3T \\\\\n",
    "(w_n, w_e, w_a) & \\text{if } 0.3T \\leq t < 0.7T \\\\\n",
    "(0.7w_n, 0.8w_e, 1.3w_a) & \\text{if } t \\geq 0.7T \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $w_n, w_e, w_a$: Base weights for accuracy, diversity, and entropy  \n",
    "- $T$: Total time steps  \n",
    "- $t$: Current time step  \n",
    "\n",
    "#### 3. Autocatalytic Assembly Dynamics\n",
    "\n",
    "The assembly complexity grows according to: \n",
    "\n",
    "$$\n",
    "A_{\\text{sys}}^{(t)} = \\frac{1}{|\\mathcal{P}|} \\sum_{i=1}^{|\\mathcal{P}|} e^{a_i} \\cdot \\frac{n_i - 1}{|\\mathcal{P}|}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $A_{\\text{sys}}^{(t)}$: System assembly complexity at time $t$  \n",
    "- $|\\mathcal{P}|$: Population size  \n",
    "- $a_i$: Assembly complexity of module $i$  \n",
    "- $n_i$: Copy number of module type $i$  \n",
    "\n",
    "Assembly Theorem: Under controlled catalysis, the system complexity $A_{\\text{sys}}^{(t)}$ is bounded by: \n",
    "\n",
    "$$\n",
    "A_{\\text{sys}}^{(t)} \\leq C \\cdot \\log(t) + A_0\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $C$: Constant  \n",
    "- $A_0$: Initial complexity  \n",
    "- $t$: Time step  \n",
    "\n",
    "Proof Sketch: The exponential assembly growth is constrained by the bias elimination mechanism and survivor selection, creating a logarithmic upper bound.\n",
    "\n",
    "#### 4. Bias Elimination Mechanism\n",
    "\n",
    "The system implements an adaptive bias detection function: \n",
    "\n",
    "$$\n",
    "\\text{Bias}(m_i, t) = \\max_k P(y_i = k | \\mathbf{x}) - \\text{threshold}(t)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\text{Bias}(m_i, t)$: Bias for module $i$ at time $t$  \n",
    "- $P(y_i = k | \\mathbf{x})$: Probability of class $k$ given input $\\mathbf{x}$  \n",
    "- $\\text{threshold}(t)$: Adaptive threshold at time $t$  \n",
    "\n",
    "Where $\\text{threshold}(t) = 0.75 + 0.2 \\cdot \\frac{t}{T}$ creates an adaptive tolerance.\n",
    "\n",
    "- $T$: Total time steps  \n",
    "- $t$: Current time step  \n",
    "\n",
    "Anti-Convergence Theorem: The bias elimination ensures population diversity: \n",
    "\n",
    "$$\n",
    "\\lim_{t \\rightarrow \\infty} \\mathbb{E}[\\text{Entropy}(\\mathcal{P}^{(t)})] \\geq H_{\\min} > 0\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\mathbb{E}[\\text{Entropy}(\\mathcal{P}^{(t)})]$: Expected entropy of population at time $t$  \n",
    "- $H_{\\min}$: Minimum entropy bound  \n",
    "\n",
    "#### 5. Message Passing and Information Flow\n",
    "\n",
    "For each module $m_i$, select neighbors by manifold distance: \n",
    "\n",
    "$$\n",
    "\\mathcal{N}_{\\mathcal{M}}(m_i) = \\{m_j : d_{\\mathcal{M}}(\\mathbf{p}_i, \\mathbf{p}_j) \\text{ among } k \\text{ smallest}\\}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\mathcal{N}_{\\mathcal{M}}(m_i)$: Set of $k$ nearest neighbors to $m_i$ on the manifold  \n",
    "- $d_{\\mathcal{M}}(\\mathbf{p}_i, \\mathbf{p}_j)$: Manifold distance between $i$ and $j$  \n",
    "- $k$: Number of neighbors  \n",
    "\n",
    "Information propagates via manifold-aware messaging: \n",
    "\n",
    "$$\n",
    "\\mathbf{M}_i^{(t)} = \\sigma(g_i) \\cdot \\frac{1}{|\\mathcal{N}_{\\mathcal{M}}(m_i)|} \\sum_{j \\in \\mathcal{N}_{\\mathcal{M}}(m_i)} \\frac{\\mathbf{h}_j^{(t-1)}}{1 + d_{\\mathcal{M}}(\\mathbf{p}_i, \\mathbf{p}_j)}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\mathbf{M}_i^{(t)}$: Message received by module $i$ at time $t$  \n",
    "- $\\sigma(g_i)$: Activation function applied to gating variable $g_i$  \n",
    "- $|\\mathcal{N}_{\\mathcal{M}}(m_i)|$: Number of neighbors  \n",
    "- $\\mathbf{h}_j^{(t-1)}$: Hidden state of neighbor $j$ at previous time  \n",
    "- $d_{\\mathcal{M}}(\\mathbf{p}_i, \\mathbf{p}_j)$: Manifold distance  \n",
    "\n",
    "Information Flow Theorem: Under connected manifold topology, information propagates globally in $O(\\log n)$ steps.\n",
    "\n",
    "#### 6. Main Convergence Proof\n",
    "\n",
    "Theorem (AAN-Q Global Convergence): Under the following conditions:\n",
    "\n",
    "- Bounded fitness landscape: $F: \\mathcal{S} \\rightarrow [0,1]$\n",
    "- Sufficient exploration: $\\epsilon$-greedy Q-learning with $\\epsilon > 0$\n",
    "- Controlled bias elimination: $|\\text{eliminated}| \\leq \\alpha |\\mathcal{P}|$ per step\n",
    "- Manifold Lipschitz continuity: $|F(\\mathbf{p}_1) - F(\\mathbf{p}_2)| \\leq L \\cdot d_{\\mathcal{M}}(\\mathbf{p}_1, \\mathbf{p}_2)$\n",
    "\n",
    "The system converges to a stable configuration: \n",
    "\n",
    "$$\n",
    "\\lim_{t \\rightarrow \\infty} \\mathbb{E}[F_{\\text{best}}^{(t)}] = F^* - \\delta\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\mathbb{E}[F_{\\text{best}}^{(t)}]$: Expected best fitness at time $t$  \n",
    "- $F^*$: Optimal fitness  \n",
    "- $\\delta$: Exploration-exploitation gap  \n",
    "\n",
    "Proof Strategy:\n",
    "\n",
    "- Q-Learning Convergence: Standard MDP theory guarantees $Q_i \\rightarrow Q_i^*$\n",
    "- Manifold Regularization: The geodesic distance creates smooth fitness landscapes\n",
    "- Population Dynamics: Bias elimination prevents premature convergence\n",
    "- Assembly Constraints: Bounded complexity prevents runaway growth\n",
    "\n",
    "#### 7. Computational Complexity\n",
    "\n",
    "The algorithm has complexity:\n",
    "\n",
    "Per Step: $O(n^2 d + n \\cdot |Q|)$ where $n = |\\mathcal{P}|$, $d$ = manifold dimension\n",
    "\n",
    "Overall: $O(T \\cdot n^2 d)$ for $T$ evolution steps\n",
    "\n",
    "Where:  \n",
    "- $n$: Population size  \n",
    "- $d$: Manifold dimension  \n",
    "- $|Q|$: Size of Q-table or Q-function  \n",
    "- $T$: Number of evolution steps  \n",
    "\n",
    "#### 8. System Complexity\n",
    "\n",
    "**8.1 Assembly Theory Metric**\n",
    "\n",
    "$$\n",
    "A_{\\text{sys}}^{(t)} = \\frac{1}{|\\mathcal{P}|} \\sum_{i=1}^{|\\mathcal{P}|} e^{a_i} \\cdot \\frac{n_i - 1}{|\\mathcal{P}|}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $A_{\\text{sys}}^{(t)}$: System assembly complexity at time $t$  \n",
    "- $|\\mathcal{P}|$: Population size  \n",
    "- $a_i$: Assembly complexity of module $i$  \n",
    "- $n_i$: Copy number of module type $i$  \n",
    "\n",
    "Each neural module (`ConceptModule`) tracks the minimal assembly complexity of it's weights. \n",
    "- Each layer's weights are wrapped in `ARCENET.core.ModuleComponent` that records the pathway\n",
    "- When a module is mutated, new components are created with parent references, enabling reuse tracking\n",
    "- The per-layer and total assemble complexity can be queried for any module with `ARCENET.models.arcnet_learner.system_assembly_complexity`\n",
    "- System-level complexity is computed as the formula above, using the sum of exponentiated assembly indicies\n",
    "\n",
    "#### 9. Complete System Evolution\n",
    "\n",
    "The system evolves according to: \n",
    "\n",
    "$$\n",
    "\\mathcal{P}^{(t+1)} = \\text{Select}(\\mathcal{P}^{(t)}) \\cup \\text{Mutate}(\\text{Select}(\\mathcal{P}^{(t)}), Q^{(t)})\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\mathcal{P}^{(t)}$: Population at time $t$  \n",
    "- $\\text{Select}(\\cdot)$: Selection operator  \n",
    "- $\\text{Mutate}(\\cdot, Q^{(t)})$: Mutation operator using Q-function $Q^{(t)}$  \n",
    "\n",
    "With the objective of maximizing: \n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathbb{E}_{t,i}\\left[ R(m_i^{(t)}) \\right] - \\lambda A_{\\text{sys}}^{(t)}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\mathcal{L}$: Objective function  \n",
    "- $R(m_i^{(t)})$: Reward for module $i$ at time $t$  \n",
    "- $\\lambda$: Regularization parameter  \n",
    "- $A_{\\text{sys}}^{(t)}$: System assembly complexity at time $t$  \n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b07672bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163df87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8279d7a7151a44f196b5a9f31a6439b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred weights for layer ea180341-98c5-4417-8143-038bfcd351a1\n",
      "Epoch 0 Loss: 1.0006 | Action: add\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torchvision')\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from core.blueprint import ArchitectureBlueprint\n",
    "from core.registry import ComponentRegistry\n",
    "from evolution.mutation import mutate_blueprint\n",
    "from evolution.controller import MutationRLController\n",
    "from evolution.transfer import transfer_weights\n",
    "from models.multimodal_learner import MultimodalLearner\n",
    "from core.components import TrackedLayer\n",
    "from data.loader import CombinedDataset\n",
    "from data.image_adapter import ImageAdapter\n",
    "from data.text_adapter import TextAdapterDistilbert\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "dataset = CombinedDataset(mnist_data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "blueprint = ArchitectureBlueprint()\n",
    "registry = ComponentRegistry()\n",
    "controller = MutationRLController()\n",
    "\n",
    "init_layer = TrackedLayer(128, 64)\n",
    "blueprint.add_module(init_layer)\n",
    "registry.register(init_layer)\n",
    "\n",
    "adapters = {'image': ImageAdapter(), 'text': TextAdapterDistilbert()}\n",
    "model = MultimodalLearner(blueprint, adapters)\n",
    "#model = model.to(device)\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    total_loss = 0\n",
    "    progress = tqdm(dataloader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "    for batch in progress:\n",
    "        x, target = batch\n",
    "        output = model(x)\n",
    "        loss = torch.nn.functional.mse_loss(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    loss_history.append(avg_loss)\n",
    "\n",
    "    state = controller.get_state(loss_history, blueprint)\n",
    "    action = controller.select_action(state)\n",
    "    mutate_blueprint(blueprint, registry)\n",
    "    new_model = MultimodalLearner(blueprint, adapters)\n",
    "    transfer_weights(model, new_model)\n",
    "    model = new_model\n",
    "    next_state = controller.get_state(loss_history, blueprint)\n",
    "    controller.update(state, action, -avg_loss, next_state)\n",
    "    print(f\"Epoch {epoch} Loss: {avg_loss:.4f} | Action: {action}\")\n",
    "\n",
    "    blueprint.visualize(filename=f\"architecture_epoch_{epoch}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16836d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1000x600>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "blueprint.visualize(filename=\"assembly_graph.png\")\n",
    "Image.open(\"assembly_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22cdb047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Stats:\n",
      "MultimodalLearner(\n",
      "  (fusion): CrossModalFusion(\n",
      "    (attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (core): ModularGeneralLearner(\n",
      "    (layers): ModuleList(\n",
      "      (0): TrackedLayer(\n",
      "        (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total Parameters: 90816\n",
      "Final Average Loss: 1.0006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.50      0.05         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.33      1.00      0.50         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.00      0.00      0.00         2\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         6\n",
      "          32       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         3\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         2\n",
      "          61       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.02        96\n",
      "   macro avg       0.01      0.03      0.01        96\n",
      "weighted avg       0.00      0.02      0.01        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming output and target are tensors, move to cpu and convert to numpy\n",
    "y_true = target.cpu().detach().numpy()\n",
    "y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "# If this is a classification task, get predicted classes\n",
    "if y_pred.ndim > 1 and y_pred.shape[1] > 1:\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    y_true_classes = y_true.argmax(axis=1) if y_true.ndim > 1 and y_true.shape[1] > 1 else y_true\n",
    "else:\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "    y_true_classes = y_true.astype(int)\n",
    "\n",
    "print(\"Final Model Stats:\")\n",
    "print(model)\n",
    "print(f\"Total Parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Final Average Loss: {avg_loss:.4f}\")\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ef804dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All components in the assembly:\n",
      "TrackedLayer(\n",
      "  (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"All components in the assembly:\")\n",
    "for component in blueprint.modules:\n",
    "    print(component)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
